# EyeCore Data Schemas - Cloud Integration Guide\n\n## Overview\n\nThis directory contains all data schemas and structures being collected by EyeCore MVP v0.2.0. Use these schemas to configure your cloud infrastructure, databases, and data pipelines.\n\n## Quick Start for Data Engineers\n\n1. Review the main data structure: `EyeCoreData.schema.json`\n2. Configure your database tables based on individual schemas\n3. Set up API ingestion endpoints to receive JSON from EyeCore\n4. Implement retention policies based on `data_retention.md`\n5. Configure ETL pipelines from local collection to cloud storage\n\n## Available Schemas\n\n### Core Schema\n- **EyeCoreData.schema.json** - Main data container (collected every 5 seconds)\n\n### Data Component Schemas\n1. **SystemMetrics.schema.json** - CPU, Memory, Disk usage\n2. **ProcessData.schema.json** - Active applications and windows\n3. **InputMetrics.schema.json** - Mouse and keyboard activity counts\n4. **FocusMetrics.schema.json** - Focus level and engagement\n5. **NetworkMetrics.schema.json** - Network connectivity data\n6. **VoiceData.schema.json** - Voice analysis (opt-in)\n7. **CameraData.schema.json** - Facial emotion data (opt-in)\n8. **KeystrokeDynamics.schema.json** - Typing patterns (opt-in)\n9. **ScreenInteractions.schema.json** - UI interaction data\n10. **FileMetadata.schema.json** - File access patterns (opt-in)\n11. **SystemEvents.schema.json** - Power and peripheral events\n12. **MouseDynamics.schema.json** - Mouse movement analytics\n13. **NetworkActivityMetadata.schema.json** - Network inference data\n\n### Supporting Schemas\n- **AggregatedStats.schema.json** - Session-wide statistics\n- **CollectionStatus.schema.json** - Collection health status\n\n## Data Flow Architecture\n\n```\nEyeCore Local Service (127.0.0.1:3000)\n    ↓\n[Collection Every 5 seconds]\n    ├─ System Metrics\n    ├─ Process Data\n    ├─ Input Metrics\n    ├─ Voice Data (if enabled)\n    ├─ Camera Data (if enabled)\n    ├─ Keystroke Dynamics (if enabled)\n    ├─ Screen Interactions\n    ├─ File Metadata (if enabled)\n    ├─ System Events\n    ├─ Mouse Dynamics\n    └─ Network Metadata\n    ↓\n[REST API Endpoints]\n    ├─ GET /data/latest (all current data)\n    ├─ GET /data/history (time series)\n    ├─ GET /data/stats (aggregated)\n    └─ Individual endpoints (/data/voice, /data/camera, etc.)\n    ↓\n[Cloud Ingestion Layer]\n    ├─ API Gateway (authentication, rate limiting)\n    ├─ Message Queue (Kafka/RabbitMQ for buffering)\n    └─ Stream Processor (real-time transformation)\n    ↓\n[Cloud Storage]\n    ├─ Time Series DB (InfluxDB/TimescaleDB)\n    ├─ Data Lake (S3/GCS)\n    └─ Analytics DB (BigQuery/Redshift)\n```\n\n## Integration Steps\n\n### Step 1: Schema Review\nEach schema includes:\n- Field names and types\n- Field descriptions\n- Value ranges and constraints\n- Privacy classifications\n- Collection frequency\n\n### Step 2: Database Design\nFor each schema:\n1. Create normalized tables\n2. Index on `timestamp` and `session_id`\n3. Partition by date for time-series data\n4. Set retention based on data sensitivity\n\n### Step 3: API Integration\nSet up ingest endpoint to receive:\n```bash\nPOST /api/v1/eyecore/ingest\nContent-Type: application/json\nAuthorization: Bearer <token>\n\n{\n  \"session_id\": \"uuid\",\n  \"timestamp\": \"2025-10-25T21:26:11Z\",\n  \"data\": { ... }\n}\n```\n\n### Step 4: Stream Processing\nImplement ETL to:\n1. Extract: Pull from EyeCore APIs every 5-30 seconds\n2. Transform: Normalize, validate, enrich with metadata\n3. Load: Store to appropriate tables/buckets\n\n### Step 5: Real-Time Analytics\nSet up dashboards for:\n- User focus trends\n- Productivity metrics\n- System health\n- Stress/fatigue indicators\n\n## Data Collection Intervals\n\n| Data Type | Frequency | Volume/Collection | Retention |\n|-----------|-----------|-------------------|----------|\n| System Metrics | Every 5s | ~1 KB | 90 days |\n| Process Data | Every 5s | ~500 B | 30 days |\n| Voice Data | Every 5s | ~300 B | 7 days (sensitive) |\n| Camera Data | Every 5s | ~400 B | 7 days (sensitive) |\n| Keystroke Dynamics | Every 5s | ~350 B | 7 days (sensitive) |\n| Screen Interactions | Every 5s | ~600 B | 30 days |\n| File Metadata | Every 5s | ~500 B | 7 days (sensitive) |\n| Network Metadata | Every 5s | ~400 B | 30 days |\n| Mouse Dynamics | Every 5s | ~450 B | 30 days |\n| System Events | Variable | ~200 B | 90 days |\n\n**Estimated Daily Volume per User:**\n- ~8.5 GB per day (uncompressed)\n- ~1.5 GB per day (compressed)\n- ~10,000+ records per user per day\n\n## Privacy and Compliance\n\n### Data Classification\n\n**Public (No Consent Required):**\n- System Metrics\n- Process Data (window titles only)\n- Input Metrics (counts only)\n- Focus Metrics\n- Screen Interactions (abstract types)\n- System Events\n- Mouse Dynamics (no coordinates)\n- Network Metadata (no packet inspection)\n\n**Sensitive (Opt-In Consent Required):**\n- Voice Data\n- Camera Data\n- Keystroke Dynamics\n- File Metadata\n\n### Compliance Requirements\n\n1. **GDPR Compliance**\n   - Store `enabled` flag for each sensitive data type\n   - Implement right to be forgotten (deletion on request)\n   - Obtain explicit consent before collection\n   - Log all data access\n\n2. **Data Residency**\n   - Store in region specified by user\n   - Do not cross borders without consent\n   - Implement encryption in transit and at rest\n\n3. **Retention Policies**\n   - Sensitive data: 7 days default\n   - General data: 30 days default\n   - System data: 90 days default\n   - Allow user configuration\n\n## Example: Setting Up PostgreSQL for EyeCore Data\n\n```sql\n-- Create main table\nCREATE TABLE eyecore_data (\n    id BIGSERIAL PRIMARY KEY,\n    session_id UUID NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL,\n    system_metrics JSONB,\n    process_data JSONB,\n    input_metrics JSONB,\n    focus_metrics JSONB,\n    network_metrics JSONB,\n    voice_data JSONB,\n    camera_data JSONB,\n    keystroke_dynamics JSONB,\n    screen_interactions JSONB,\n    file_metadata JSONB,\n    system_events JSONB,\n    mouse_dynamics JSONB,\n    network_activity_metadata JSONB,\n    created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Create indexes for performance\nCREATE INDEX idx_eyecore_session ON eyecore_data(session_id);\nCREATE INDEX idx_eyecore_timestamp ON eyecore_data(timestamp);\nCREATE INDEX idx_eyecore_session_time ON eyecore_data(session_id, timestamp);\n\n-- Partition by date for large datasets\nCREATE TABLE eyecore_data_2025_10 PARTITION OF eyecore_data\n    FOR VALUES FROM ('2025-10-01') TO ('2025-11-01');\n```\n\n## Example: CloudSQL/BigQuery Setup\n\n```python\n# Python example for BigQuery ingest\nfrom google.cloud import bigquery\nimport json\nfrom datetime import datetime\n\nclient = bigquery.Client()\ntable_id = \"project.dataset.eyecore_data\"\n\ndef ingest_eyecore_data(data_json):\n    errors = client.insert_rows_json(\n        table_id,\n        [{\n            \"session_id\": data_json[\"session_id\"],\n            \"timestamp\": data_json[\"timestamp\"],\n            \"data_json\": json.dumps(data_json),\n            \"ingested_at\": datetime.utcnow().isoformat()\n        }]\n    )\n    return len(errors) == 0\n```\n\n## Monitoring and Alerting\n\n### Key Metrics to Monitor\n\n1. **Data Pipeline Health**\n   - Ingestion latency (target: <1 min)\n   - Message queue depth\n   - Failed record count\n   - Data freshness\n\n2. **Data Quality**\n   - Null value rates\n   - Out-of-range values\n   - Duplicate records\n   - Schema violations\n\n3. **Storage**\n   - Daily data volume\n   - Storage growth rate\n   - Retention policy compliance\n   - Compression ratio\n\n### Example Alerts\n\n```yaml\nalerts:\n  - name: \"Ingestion Latency High\"\n    threshold: 5 minutes\n    severity: WARNING\n\n  - name: \"Failed Records\"\n    threshold: 100 records/hour\n    severity: CRITICAL\n\n  - name: \"Storage Quota\"\n    threshold: 80% used\n    severity: WARNING\n\n  - name: \"Data Freshness\"\n    threshold: >2 hours old\n    severity: CRITICAL\n```\n\n## File Organization\n\n```\ndata_schemas/\n├── README.md                                    # This file\n├── EyeCoreData.schema.json                      # Main schema\n├── component_schemas/\n│   ├── SystemMetrics.schema.json\n│   ├── ProcessData.schema.json\n│   ├── InputMetrics.schema.json\n│   ├── FocusMetrics.schema.json\n│   ├── NetworkMetrics.schema.json\n│   ├── VoiceData.schema.json\n│   ├── CameraData.schema.json\n│   ├── KeystrokeDynamics.schema.json\n│   ├── ScreenInteractions.schema.json\n│   ├── FileMetadata.schema.json\n│   ├── SystemEvents.schema.json\n│   ├── MouseDynamics.schema.json\n│   └── NetworkActivityMetadata.schema.json\n├── supporting_schemas/\n│   ├── AggregatedStats.schema.json\n│   └── CollectionStatus.schema.json\n├── sql/\n│   ├── postgresql_schema.sql\n│   ├── bigquery_schema.sql\n│   └── dynamodb_schema.json\n├── terraform/\n│   ├── main.tf\n│   ├── variables.tf\n│   └── outputs.tf\n├── data_retention.md\n├── privacy_compliance.md\n└── cloud_setup_guide.md\n```\n\n## Support for Data Engineers\n\nFor questions or custom integrations:\n\n1. **Schema Questions**: Review the individual `.schema.json` files\n2. **Data Volume Estimation**: See \"Data Collection Intervals\" table above\n3. **Privacy Requirements**: See `privacy_compliance.md`\n4. **SQL Examples**: See `sql/` directory\n5. **Infrastructure as Code**: See `terraform/` directory\n\n## Next Steps\n\n1. ✅ Review this README\n2. ✅ Download all JSON schemas\n3. ✅ Create database schema\n4. ✅ Set up API ingest endpoint\n5. ✅ Configure data pipeline\n6. ✅ Set up monitoring\n7. ✅ Test with sample data\n8. ✅ Deploy to production\n\n---\n\n**Last Updated:** October 25, 2025  \n**EyeCore Version:** 0.2.0  \n**Status:** Production Ready\n